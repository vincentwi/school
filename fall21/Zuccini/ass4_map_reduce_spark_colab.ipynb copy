{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfstpKhUM8x7"
   },
   "source": [
    "<h1><center>Big Data Algorithms Techniques & Platforms</center></h1>\n",
    "<h2>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>Assignment 4 - MapReduce and Spark</center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWwndZSiM8x8"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "In this exercise you is asked to use Spark for implementing an algorithm that applies computations on documents and dataframes.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "<hr style=\" border:none; height:2px;\">\n",
    " <font  size=\"3\" color='#91053d'>**Execute the following cell in order to initialize Spark**</font>\n",
    "<hr style=\" border:none; height:2px;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3shtJGpOM8x8",
    "outputId": "8b100790-dcef-44a6-da62-524a60617907"
   },
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n",
    "!tar zxvf spark-3.0.3-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\"\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "#import of the SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#inizialization of the Spark Session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Assignment4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "import pandas as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK49MFw9M8yA"
   },
   "source": [
    "# Analysing documents\n",
    "\n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "We have already seen that MapReduce procedures are good in analyzing text-files.\n",
    "    \n",
    "The provided data comes from a scraping operation on the website https://www.vagalume.com.br/ and is available on kaggle:\n",
    "    \n",
    "https://www.kaggle.com/neisse\n",
    "    \n",
    "\n",
    "    \n",
    "The assignment is divided in 2 parts:\n",
    "    \n",
    "* Part 1 is focused on MapReduce \n",
    "    \n",
    "* Part 2  is focuses on dataframes\n",
    "    </font>\n",
    "    </p>\n",
    "    \n",
    "<p align=\"justify\">\n",
    "<hr style=\" border:none; height:2px;\">\n",
    " <font  size=\"3\" color='#91053d'>Notice that  dataset is noisy and shows all the typical issues related with data coming from this procedure (duplicated entries, etc).</font>\n",
    "<hr style=\" border:none; height:2px;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK49MFw9M8yA"
   },
   "source": [
    "# Part 1 -  MapReduce\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "In the provided folder you can find a set of documents/files containing  descriptions of songs (lyrics and additional informations). Specifically in each file:\n",
    "\n",
    "- the first line is the idiom/language\n",
    "- the second line is the title of a song\n",
    "- the third line is the relative url of the song of the original website\n",
    "- from fourth line on the text you find the lyrics of the song.\n",
    "    </font>\n",
    "    </p>\n",
    "\n",
    "## Exercise 1 - (2 points) - Song's lyrics \n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "Provide a Spark MapReduce procedure that reads the documents and checks how many song's lyrics appear at least two times.\n",
    "\n",
    "In the data-interpretation of this exercise you can consider that two files represent the same lyric if the url (3rd line of each file) is the same.\n",
    "\n",
    " </font>\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "<hr style=\" border:none; height:2px;\">\n",
    " <font  size=\"3\" color='#91053d'>Notice that  you can reuse any code that was made available for the previous labs/assignments or that you already developed in these contexts.</font>\n",
    "<hr style=\" border:none; height:2px;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write here your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK49MFw9M8yA"
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "### 2.1 - (1 point) - Distinct songs\n",
    "Provide a Spark MapReduce procedure that provides how many distinct song's lyrics are present.\n",
    "\n",
    "Also in this case consider the uri as key: two files represent the same lyric if the url is equal.\n",
    "\n",
    "### 2.2 - (1 point) - Chaining MapReduce steps\n",
    "According to your implementation of Exercise 1, can you chain MapReduce additional MapReduce steps for solving Exercise 2.1? \n",
    "\n",
    "Provide the code for 2.1 and anwer for 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write here your code followed by the answer to question 2.2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "### 3.1 - (3 points) - Most common word for language\n",
    "\n",
    "Now that you discovered the duplicated documents consider just one occurence of each song's lyric and define a MapReduce procedure that finds the most common word for each language (of course you must remove stop words).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write here your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - (3 points) - Most common end/start words\n",
    "\n",
    "Finally discover, for each language, the most common ending and starting word (of course, also in this case) you must remove stop words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write here your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-QgxsF1M8yB"
   },
   "source": [
    "\n",
    "<p align=\"justify\">\n",
    "<hr style=\" border:none; height:2px;\">\n",
    " <font  size=\"3\" color='#91053d'>**DataFrames**</font>\n",
    "<hr style=\" border:none; height:2px;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBkYMzzIM8yB",
    "outputId": "2f6a99b7-c42d-4401-9a7b-96628f3a0472"
   },
   "source": [
    "# Part 2 - Dataframes\n",
    "\n",
    "In this part you can use Pandas Dataframes or  Spark Dataframes.  I suggest to use a Spark Dataframe\n",
    "end exploit the Pandas functionalities as we have seen in the 2nd assignment. Download the two available datasets at the link:\n",
    "\n",
    "https://www.kaggle.com/neisse/scrapped-lyrics-from-6-genres\n",
    "\n",
    "You can find two .cvs files: \n",
    "\n",
    "* artists-data.csv\n",
    "\n",
    "* lyrics-data.csv\n",
    "\n",
    "\n",
    "# Import artist data.\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "The artist data in the .csv file can be stored in a dataframe. \n",
    "    \n",
    "Each row of the .csv file describes an artist and the columns represent the following data:\n",
    "    \n",
    "* Artist - The artist's name\n",
    "* Popularity - Popularity score at the date of scrapping\n",
    "* ALink - The link to the artist's page\n",
    "* AGenre - Primary musical genre of the artist\n",
    "* AGenres - A list (pay attention to the format) of genres the artist fits in\n",
    "    \n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n",
    "# Import song's lyrics data.\n",
    "\n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "    \n",
    "Each row of the .csv file describes a lyric and the columns represent the following data:\n",
    "    \n",
    "* ALink - The link to the webpage of the artist\n",
    "* SLink - The link to the webpage of the song\n",
    "* Idiom - The idiom of the lyric\n",
    "* Lyric - The lyrics\n",
    "* SName - The name of the song\n",
    "\n",
    "    \n",
    "\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQn1a3PqM80l"
   },
   "source": [
    "#  Exercise 4 - (3 points) - Artist's genre\n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "Provide a program that finds the artists for which the genre is not specified.\n",
    "\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0liD2NOVM8yE",
    "outputId": "65272f02-1a32-4761-dcc4-53c39179d391"
   },
   "outputs": [],
   "source": [
    "### Write here your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exercise 5 - (3 points) - Duplicates\n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "Provide a program that removes the duplicates in the artists (also in this case the URL is the key).\n",
    "\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write here your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exercise 6 - (4 points)\n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "Provide a program that using dataframe return the 100 most popular artists and the lyrics of their songs.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write here your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DatBVcKUM8yn"
   },
   "source": [
    "# 2 - Bonus \n",
    "\n",
    "\n",
    "<p align=\"justify\">\n",
    "<font size=\"3\">\n",
    "Using the approach you prefer (just Dataframes, hybrid approach)  :\n",
    "    \n",
    "* the 10 most common words in the lyrics of each artist\n",
    "* the 10 most common words for each genre. For this question we can use the primary genre of the artist.\n",
    "\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3EIzkQFM8yo"
   },
   "outputs": [],
   "source": [
    "# Write here your code and the detailed description of the MapReduce algorithm.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "ass4-map-reduce-spark-colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "name": "BE4-Spark.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
