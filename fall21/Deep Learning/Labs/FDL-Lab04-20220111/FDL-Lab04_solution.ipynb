{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qd5jTBqLw8qp",
    "outputId": "baddda86-e408-49be-f09f-74b74ecb3bb8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#from google.colab import drive\n",
    "\n",
    "## load train, test and validation label arrays\n",
    "#drive = drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVlQQXhP3MsA",
    "outputId": "6f7cb40d-0c2f-4476-c058-a76edbc4fa32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "##here put your custom destination folder\n",
    "images=list(glob.glob(os.path.join(\"./DL_LAB_4/DogsCats_Train.zip (Unzipped Files)/DogsCats_Train/*.jpg\")))\n",
    "random.shuffle(images)\n",
    "train = images[:800]\n",
    "val = images[800:]\n",
    "print(len(images))\n",
    "print(np.asarray(train).shape, np.asarray(val).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iAk1iyhPxmCR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_list):\n",
    "\n",
    "        ##Load array of images\n",
    "        self.images = image_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ## Get the image-label set \n",
    "        image = io.imread(self.images[index]) \n",
    "        image = np.transpose(image, (2,0,1))\n",
    "        image = image/255.0\n",
    "        if 'dog' in self.images[index]:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        ## return the total number of data samples\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Hl8hHxx60rvI"
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train)\n",
    "val_dataset = MyDataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "p4EktChmzoDU"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader( train_dataset, batch_size=10, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader( val_dataset, batch_size=10, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sgZoMLKy0n41"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=2, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 32, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 128, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 256, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # Allow for accessing forward method in a inherited class\n",
    "    forward = _forward\n",
    "\n",
    "\n",
    "def _resnet(arch, block, layers, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EUK7UxZe2Oej"
   },
   "outputs": [],
   "source": [
    "net_args = {\n",
    "    \"block\": BasicBlock,\n",
    "    \"layers\": [2, 2, 2, 2]\n",
    "}\n",
    "model = ResNet(**net_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OMmHRqrx2Okj"
   },
   "outputs": [],
   "source": [
    "# define optimizer, criterion and number of training epochs\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSE0cN_m2OcA",
    "outputId": "521ff78e-95b9-4aa0-a285-7f26e273a801"
   },
   "outputs": [],
   "source": [
    "#!pip install torchnet\n",
    "import torchnet as tnt\n",
    "\n",
    "# define confusion matrix using tnt package\n",
    "confusion_matrix = tnt.meter.ConfusionMeter(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JRZ7R77c3Tm4"
   },
   "outputs": [],
   "source": [
    "# create a directory for saving the models and the training progress\n",
    "save_folder = './DL_LAB_4/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uXopSOpH3TqG"
   },
   "outputs": [],
   "source": [
    "def write_results(ff, save_folder, epoch, train_acc, val_acc, train_loss, val_loss):\n",
    "    ff=open('{}/progress.txt'.format(save_folder),'a')\n",
    "    ff.write(' E: ')\n",
    "    ff.write(str(epoch))\n",
    "    ff.write('         ')\n",
    "    ff.write(' TRAIN_OA: ')\n",
    "    ff.write(str('%.3f' % train_acc))\n",
    "    ff.write(' VAL_OA: ')\n",
    "    ff.write(str('%.3f' % val_acc))\n",
    "    ff.write('         ')\n",
    "    ff.write(' TRAIN_LOSS: ')\n",
    "    ff.write(str('%.3f' % train_loss))\n",
    "    ff.write(' VAL_LOSS: ')\n",
    "    ff.write(str('%.3f' % val_loss))\n",
    "    ff.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GqeouwJG3Tu2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# create a function that creates train-val loss graph and saves the figure in a destination folder\n",
    "def save_graph(train_loss, val_loss, nb_epochs, save_folder):\n",
    "    plt.plot(list(range(nb_epochs+1))[1:], train_loss)\n",
    "    plt.plot(list(range(nb_epochs+1))[1:], val_loss)\n",
    "    plt.legend(['train', 'val'])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('{}/chart.png'.format(save_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DH2f895q3Ttk",
    "outputId": "97893484-df1d-45ea-9c28-a84402e859f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/80 [00:00<00:08,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 1/10) [0/80 (0%)]\tLoss: 0.684081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:01<00:04, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 1/10) [20/80 (25%)]\tLoss: 0.701454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [00:03<00:02, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 1/10) [40/80 (50%)]\tLoss: 0.715183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [00:04<00:01, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 1/10) [60/80 (75%)]\tLoss: 0.661240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:06<00:00, 12.33it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 34.60it/s]\n",
      "  2%|▎         | 2/80 [00:00<00:06, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[66 39]\n",
      " [59 36]]\n",
      "TRAIN_LOSS:  0.698 TRAIN_ACC:  51.500\n",
      "VAL_LOSS:  0.702 VAL_ACC:  51.000\n",
      "Train (epoch 2/10) [0/80 (0%)]\tLoss: 0.756036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [00:02<00:05,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 2/10) [20/80 (25%)]\tLoss: 0.688626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/80 [00:03<00:03, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 2/10) [40/80 (50%)]\tLoss: 0.660277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 63/80 [00:05<00:01, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 2/10) [60/80 (75%)]\tLoss: 0.630085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:07<00:00, 11.25it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 37.19it/s]\n",
      "  2%|▎         | 2/80 [00:00<00:05, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[65 40]\n",
      " [44 51]]\n",
      "TRAIN_LOSS:  0.687 TRAIN_ACC:  54.000\n",
      "VAL_LOSS:  0.681 VAL_ACC:  58.000\n",
      "Train (epoch 3/10) [0/80 (0%)]\tLoss: 0.688809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:01<00:05, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 3/10) [20/80 (25%)]\tLoss: 0.708495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [00:03<00:03, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 3/10) [40/80 (50%)]\tLoss: 0.695250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [00:05<00:01,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 3/10) [60/80 (75%)]\tLoss: 0.725631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:07<00:00, 10.57it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 27.01it/s]\n",
      "  1%|▏         | 1/80 [00:00<00:09,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[56 49]\n",
      " [36 59]]\n",
      "TRAIN_LOSS:  0.681 TRAIN_ACC:  57.000\n",
      "VAL_LOSS:  0.686 VAL_ACC:  57.500\n",
      "Train (epoch 4/10) [0/80 (0%)]\tLoss: 0.652408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:02<00:06,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 4/10) [20/80 (25%)]\tLoss: 0.685621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [00:04<00:03,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 4/10) [40/80 (50%)]\tLoss: 0.741092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [00:06<00:01,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 4/10) [60/80 (75%)]\tLoss: 0.721534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:08<00:00,  9.20it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 29.10it/s]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[47 58]\n",
      " [28 67]]\n",
      "TRAIN_LOSS:  0.676 TRAIN_ACC:  59.500\n",
      "VAL_LOSS:  0.692 VAL_ACC:  57.000\n",
      "Train (epoch 5/10) [0/80 (0%)]\tLoss: 0.629052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:02<00:07,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 5/10) [20/80 (25%)]\tLoss: 0.731720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/80 [00:05<00:03,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 5/10) [40/80 (50%)]\tLoss: 0.691237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [00:07<00:01,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 5/10) [60/80 (75%)]\tLoss: 0.720816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:08<00:00,  8.98it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 27.98it/s]\n",
      "  1%|▏         | 1/80 [00:00<00:08,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[39 66]\n",
      " [22 73]]\n",
      "TRAIN_LOSS:  0.658 TRAIN_ACC:  61.250\n",
      "VAL_LOSS:  0.686 VAL_ACC:  56.000\n",
      "Train (epoch 6/10) [0/80 (0%)]\tLoss: 0.733524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:02<00:07,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 6/10) [20/80 (25%)]\tLoss: 0.770759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [00:04<00:04,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 6/10) [40/80 (50%)]\tLoss: 0.603290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 61/80 [00:06<00:01, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 6/10) [60/80 (75%)]\tLoss: 0.545842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:08<00:00,  8.98it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 26.88it/s]\n",
      "  1%|▏         | 1/80 [00:00<00:07,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[73 32]\n",
      " [47 48]]\n",
      "TRAIN_LOSS:  0.658 TRAIN_ACC:  61.750\n",
      "VAL_LOSS:  0.673 VAL_ACC:  60.500\n",
      "Train (epoch 7/10) [0/80 (0%)]\tLoss: 0.736770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:02<00:06,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 7/10) [20/80 (25%)]\tLoss: 0.613666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/80 [00:04<00:04,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 7/10) [40/80 (50%)]\tLoss: 0.626095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 63/80 [00:06<00:01,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 7/10) [60/80 (75%)]\tLoss: 0.623384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:08<00:00,  9.03it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 28.03it/s]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[71 34]\n",
      " [43 52]]\n",
      "TRAIN_LOSS:  0.658 TRAIN_ACC:  62.625\n",
      "VAL_LOSS:  0.686 VAL_ACC:  61.500\n",
      "Train (epoch 8/10) [0/80 (0%)]\tLoss: 0.680777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:02<00:06,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 8/10) [20/80 (25%)]\tLoss: 0.640006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [00:04<00:04,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 8/10) [40/80 (50%)]\tLoss: 0.732192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [00:06<00:01,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 8/10) [60/80 (75%)]\tLoss: 0.598261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:08<00:00,  9.12it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 25.62it/s]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[73 32]\n",
      " [48 47]]\n",
      "TRAIN_LOSS:  0.638 TRAIN_ACC:  66.375\n",
      "VAL_LOSS:  0.662 VAL_ACC:  60.000\n",
      "Train (epoch 9/10) [0/80 (0%)]\tLoss: 0.619932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:02<00:06,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 9/10) [20/80 (25%)]\tLoss: 0.692618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [00:04<00:04,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 9/10) [40/80 (50%)]\tLoss: 0.540890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [00:06<00:01,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 9/10) [60/80 (75%)]\tLoss: 0.719975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:08<00:00,  9.29it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 25.62it/s]\n",
      "  1%|▏         | 1/80 [00:00<00:09,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[85 20]\n",
      " [69 26]]\n",
      "TRAIN_LOSS:  0.628 TRAIN_ACC:  65.875\n",
      "VAL_LOSS:  0.700 VAL_ACC:  55.500\n",
      "Train (epoch 10/10) [0/80 (0%)]\tLoss: 0.605083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:02<00:06,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 10/10) [20/80 (25%)]\tLoss: 0.783530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [00:04<00:04,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 10/10) [40/80 (50%)]\tLoss: 0.589033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 61/80 [00:06<00:01,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 10/10) [60/80 (75%)]\tLoss: 0.591982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:08<00:00,  9.45it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 26.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[52 53]\n",
      " [26 69]]\n",
      "TRAIN_LOSS:  0.631 TRAIN_ACC:  65.500\n",
      "VAL_LOSS:  0.672 VAL_ACC:  60.500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "total_train_losses = []\n",
    "total_val_losses = []\n",
    "\n",
    "ff=open('{}/progress.txt'.format(save_folder),'w')\n",
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    ##TRAINING##\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    confusion_matrix.reset()\n",
    "\n",
    "    for i, batch, in enumerate(tqdm(train_dataloader)):\n",
    "        img_batch, lbl_batch = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img_batch.float())\n",
    "        loss=criterion(output, lbl_batch.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        confusion_matrix.add(output.data.squeeze(), lbl_batch.long())\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, epochs, i, len(train_dataloader),100.*i/len(train_dataloader), loss.item()))\n",
    "\n",
    "    train_acc=(np.trace(confusion_matrix.conf)/float(np.ndarray.sum(confusion_matrix.conf))) *100\n",
    "    train_loss_mean = np.mean(train_losses)\n",
    "    total_train_losses.append(train_loss_mean)\n",
    "    confusion_matrix.reset()\n",
    "\n",
    "     ##VALIDATION##\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "\n",
    "    for i, batch, in enumerate(tqdm(val_dataloader)):\n",
    "        img_batch, lbl_batch = batch\n",
    "        outputs=model(img_batch.float())\n",
    "        loss=criterion(outputs, lbl_batch.long())\n",
    "\n",
    "        confusion_matrix.add(outputs.data.squeeze(), lbl_batch.long())\n",
    "        val_losses.append(loss.item())\n",
    "\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix.conf)\n",
    "\n",
    "    val_acc=(np.trace(confusion_matrix.conf)/float(np.ndarray.sum(confusion_matrix.conf))) *100\n",
    "    val_loss_mean = np.mean(val_losses)\n",
    "    total_val_losses.append(val_loss_mean)\n",
    "\n",
    "    print('TRAIN_LOSS: ', '%.3f' % train_loss_mean, 'TRAIN_ACC: ', '%.3f' % train_acc)\n",
    "    print('VAL_LOSS: ', '%.3f' % val_loss_mean, 'VAL_ACC: ', '%.3f' % val_acc)\n",
    "    confusion_matrix.reset()\n",
    "    write_results(ff, save_folder, epoch, train_acc, val_acc, train_loss_mean, val_loss_mean)\n",
    "\n",
    "    torch.save(model.state_dict(), save_folder + '/model_{}.pt'.format(epoch))\n",
    "\n",
    "save_graph(total_train_losses, total_val_losses, epochs, save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkBI3vJS0n24",
    "outputId": "acdce669-49eb-4048-bd5e-3d103b300ab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54 46]\n",
      " [38 62]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "\n",
    "test_images=list(glob.glob(os.path.join(\"./DL_LAB_4/DogsCats_Test.zip (Unzipped Files)/DogsCats_Test/*.jpg\")))\n",
    "\n",
    "net_args = {\n",
    "    \"block\": BasicBlock,\n",
    "    \"layers\": [2, 2, 2, 2]\n",
    "}\n",
    "model = ResNet(**net_args)\n",
    "model.load_state_dict(torch.load('./DL_LAB_4/models/model_10.pt'))\n",
    "model.eval()\n",
    "\n",
    "confusion_matrix = tnt.meter.ConfusionMeter(2) \n",
    "confusion_matrix.reset()\n",
    "\n",
    "for i in range(0, len(test_images)):\n",
    "    img = io.imread(test_images[i])\n",
    "    if 'dog' in test_images[i]:\n",
    "      label = torch.tensor([0])\n",
    "    else:\n",
    "      label = torch.tensor([1])\n",
    "    img = img/255.0 #normalization\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img = np.reshape(img, (1, img.shape[0], img.shape[1], img.shape[2])) #reshape to (batchsize x channels x height x width)\n",
    "    img = torch.from_numpy(img)\n",
    "    output = F.log_softmax(model(img.float()), dim=1)\n",
    "    confusion_matrix.add(output.data, label.long())\n",
    "\n",
    "print(confusion_matrix.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_Lab3_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
