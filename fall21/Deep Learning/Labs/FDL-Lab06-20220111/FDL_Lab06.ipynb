{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6NmTqH25KQ0"
   },
   "source": [
    "# Deep Learning Course: Lab Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C71IXP2U5Ooy"
   },
   "source": [
    "In this lab exercise you will:\n",
    "\n",
    "Learn about RNN and LSTM on toy sequential tasks:\n",
    "\n",
    "Part 1: RNN and LSTM based 1D signal classifier & predictor\n",
    "\n",
    "Part 2: RNN and LSTM based names classification with a character-level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Fw7p-YI3nvh",
    "outputId": "ff6a583c-5152-4a79-98cc-4380a2941341"
   },
   "outputs": [],
   "source": [
    "### Connect to Google Drive if you are using Drive.\n",
    "from google.colab import drive\n",
    "\n",
    "drive = drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPHCncwtov9v"
   },
   "outputs": [],
   "source": [
    "# working folder\n",
    "import os\n",
    "working_dir = 'drive/MyDrive/...'\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8E9kV8Rov9v"
   },
   "outputs": [],
   "source": [
    "### Import all your libraries\n",
    "import random \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "\n",
    "import numpy as np \n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNn_q0t5ov9w"
   },
   "source": [
    "## Part 1: RNN and LSTM based 1D signal classifier & predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AclOH4wmov9w"
   },
   "source": [
    "### 1.A. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c4GKx-gu2NtO",
    "outputId": "1b0fd593-5aae-4e67-b44d-4cd33e54f0e3"
   },
   "outputs": [],
   "source": [
    "## Sine, Sawtooth, Tirangloe and Square wave generators\n",
    "def get_noise():\n",
    "    std = random.uniform(0, 0.1)\n",
    "    noise = np.random.normal(0, std, 500)\n",
    "    return noise\n",
    "\n",
    "def get_sine():\n",
    "    noise = get_noise()\n",
    "    time = np.linspace(0, 1, 500)\n",
    "    repeats = random.randrange (5, 10)\n",
    "    sine = np.sin(repeats * np.pi * time) + noise\n",
    "    return time, sine\n",
    "\n",
    "def get_triangle():\n",
    "    noise = get_noise()\n",
    "    time = np.linspace(0, 1, 500)\n",
    "    repeats = random.randrange (5, 10)\n",
    "    triangle = signal.sawtooth(repeats * np.pi * time, 0.5) + noise\n",
    "    return time, triangle\n",
    "\n",
    "def get_square():\n",
    "    noise = get_noise()\n",
    "    time = np.linspace(0, 1, 500)\n",
    "    repeats = random.randrange (5, 10)\n",
    "    square = signal.square(repeats * np.pi * time, 0.5) + noise\n",
    "    return time, square\n",
    "\n",
    "def get_sawtooth():\n",
    "    noise = get_noise()\n",
    "    time = np.linspace(0, 1, 500)\n",
    "    repeats = random.randrange (5, 10)\n",
    "    sawtooth = signal.sawtooth(repeats * np.pi * time) + noise\n",
    "    return time, sawtooth\n",
    "        \n",
    "plt.plot(*get_sine())\n",
    "plt.show()\n",
    "\n",
    "plt.plot(*get_triangle())\n",
    "plt.show()\n",
    "\n",
    "plt.plot(*get_square())\n",
    "plt.show()\n",
    "\n",
    "plt.plot(*get_sawtooth())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTBYaj3yov9x"
   },
   "source": [
    "### 1.B. RNN Wave Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vygeP_Eqov9x"
   },
   "outputs": [],
   "source": [
    "## Dataloader \n",
    "\n",
    "class WavePreloader(data.Dataset):\n",
    "\n",
    "    def __init__(self, samples=1000):\n",
    "        self.samples = samples # Total samples to be generated in the dataset\n",
    "        self.funcs = [get_sine, get_triangle, get_sawtooth, get_square] # functions to generate a sample\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cls_lbl = random.randint(0, 3) # randomly get a function to generate\n",
    "        _, inp = self.funcs[cls_lbl]() # generate wave\n",
    "        \n",
    "        return inp.reshape(-1, 1), cls_lbl # return generated wave and corresponding class label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KShB4rIXov9y"
   },
   "outputs": [],
   "source": [
    "## RNN classifier\n",
    "\n",
    "# *****START CODE\n",
    "class WaveClassifier(nn.Module):\n",
    "    def __init__(self, n_classes=4):\n",
    "        super(WaveClassifier, self).__init__()\n",
    "        # Define a 1 layer RNN which gives 8 dimensional feature map ouput\n",
    "        # Define a linear layer that takes a vector of size 8 as input and gives num classes as ouput\n",
    "        \n",
    "    def forward(self, x):\n",
    "         # create h0 tensor which has same size as input x\n",
    "         # forward pass through rnn\n",
    "         # apply linear layer to last time step of rnn output\n",
    "        return x\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmehlSA5ov9y",
    "outputId": "0d26ba82-15ba-41b7-d7c5-bf419c8700a0"
   },
   "outputs": [],
   "source": [
    "## Instantiate dataloader, optimizer, loss, and network\n",
    "\n",
    "lr = 0.01\n",
    "batch_size = 100 \n",
    "epochs = 100\n",
    "\n",
    "# *****START CODE\n",
    "# define training dataset\n",
    "# define test dataset\n",
    "\n",
    "# define train loader\n",
    "# define test loader\n",
    "\n",
    "# define a multi class loss \n",
    "# instantiate your network\n",
    "# instantiate your optimizer\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdKtBbJkov9z",
    "outputId": "4ca40f66-fff2-46a2-cde1-f4c5d0213893"
   },
   "outputs": [],
   "source": [
    "## Train your network\n",
    "\n",
    "# *****START CODE\n",
    "for epoch in range(epochs):\n",
    "    running_train_loss = []   # variable to accumulate losses\n",
    "    running_test_loss = []\n",
    "    \n",
    "    train_predictions = []    # variable to accumulate predictions and ground truth labels\n",
    "    train_ground_truths = []\n",
    "    \n",
    "    test_predictions = []\n",
    "    test_ground_truths = []\n",
    "    \n",
    "    # train loop\n",
    "    \n",
    "    model.train()\n",
    "    for inp_batch, lbl_batch in train_loader:\n",
    "    \n",
    "    # test loop\n",
    "    model.eval()\n",
    "    for inp_batch, lbl_batch in test_loader:\n",
    "      \n",
    "    # print mean epoch loss and f1 score using accumulated loss and accumulated labels\n",
    "    print (f\"\\n###### Epoch {epoch} ######\")\n",
    "    print (\"Train Loss : \", np.mean(running_train_loss))\n",
    "    print (\"Train F1 Score : \", f1_score(train_ground_truths, train_predictions, average=\"macro\"))\n",
    "    \n",
    "    print (\"Test Loss : \", np.mean(running_test_loss))\n",
    "    print (\"Test F1 Score : \", f1_score(test_ground_truths, test_predictions, average=\"macro\"))\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6NhraZGov90"
   },
   "source": [
    "### 1.C. LSTM Wave prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuVjb75_ov90"
   },
   "outputs": [],
   "source": [
    "## Dataloader \n",
    "\n",
    "class WavePredPreloader(data.Dataset):\n",
    "\n",
    "    def __init__(self, samples=1000):\n",
    "        self.samples = samples # Total samples to be generated in the dataset\n",
    "        self.funcs = [get_sine, get_triangle, get_sawtooth, get_square] # functions to generate a sample\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cls_lbl = random.randint(0, 3) # randomly get a function to generate\n",
    "        _, inp = self.funcs[cls_lbl]() # generate wave\n",
    "        first_half = inp[:250]\n",
    "        second_half = inp[250:]\n",
    "        return first_half.reshape(-1, 1), second_half.reshape(-1, 1) # return generated wave split in half as input and label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3eDB7ipov90"
   },
   "outputs": [],
   "source": [
    "## LSTM regressor\n",
    "\n",
    "# *****START CODE\n",
    "class WavePredictor(nn.Module):\n",
    "    def __init__(self, n_classes=4):\n",
    "        super(WavePredictor, self).__init__()\n",
    "        # Define a 1 layer LSTM which gives 8 dimensional feature map ouput\n",
    "        # Define a 1 layer LSTM which gives 8 dimensional input and 1 dimentionsnal ouput\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # create h0 tensor which has same size as input x\n",
    "        # create c0 tensor which has same size as input x\n",
    "        x, (hn, cn) = \n",
    "        \n",
    "        # create h0 tensor which has same size as input x\n",
    "        # create c0 tensor which has same size as input x\n",
    "        x, (hn, cn) = \n",
    "        return x\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUK-n1nDov91",
    "outputId": "ddbed685-3e05-4ae2-a450-cb02d1ccd004"
   },
   "outputs": [],
   "source": [
    "## Instantiate dataloader, optimizer, loss, and network\n",
    "\n",
    "lr = 0.0001\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "\n",
    "# *****START CODE\n",
    "# define training dataset\n",
    "# define test dataset\n",
    "\n",
    "# define train loader\n",
    "# define test loader\n",
    "\n",
    "# define a MSE loss \n",
    "# instantiate your network\n",
    "# instantiate your optimizer\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8ntrCFiov91",
    "outputId": "7eb0a292-81db-45b0-fdef-cbc4b64bbc67",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train your network\n",
    "\n",
    "# *****START CODE\n",
    "for epoch in range(epochs):\n",
    "    running_train_loss = []   # variable to accumulate losses\n",
    "    running_test_loss = []\n",
    "    \n",
    "    # train loop\n",
    "    \n",
    "    model.train()\n",
    "    for inp_batch, lbl_batch in train_loader:\n",
    "        model.zero_grad()\n",
    "    \n",
    "    # test loop\n",
    "    model.eval()\n",
    "    for inp_batch, lbl_batch in test_loader:\n",
    "      \n",
    "    # print mean epoch loss and f1 score using accumulated loss and accumulated labels\n",
    "    print (f\"\\n###### Epoch {epoch} ######\")\n",
    "    print (\"Train Loss : \", np.mean(running_train_loss))\n",
    "    \n",
    "    print (\"Test Loss : \", np.mean(running_test_loss))\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jShSsMWIov91",
    "outputId": "5442e464-acab-4044-d5b4-9ac07f5dc4b6"
   },
   "outputs": [],
   "source": [
    "# Plot some evaluation examples\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inp_batch, lbl_batch = next(iter(test_loader))\n",
    "    inp_batch = Variable(inp_batch).float()\n",
    "    lbl_batch = Variable(lbl_batch).float()\n",
    "    pred = model(inp_batch)\n",
    "\n",
    "examples_to_show = 8\n",
    "fig, axs = plt.subplots(examples_to_show//2, 2, figsize=(10,20))\n",
    "for i in range(examples_to_show):\n",
    "    axs[i//2, i%2].plot(np.arange(0,250,1), inp_batch.detach().numpy()[i])\n",
    "    axs[i//2, i%2].plot(np.arange(250,500,1), lbl_batch.detach().numpy()[i])\n",
    "    axs[i//2, i%2].plot(np.arange(250,500,1), pred.detach().numpy()[i])\n",
    "    axs[i//2, i%2].legend(['input', 'ground truth', 'prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvO6wijCov92"
   },
   "source": [
    "## Part 2: RNN and LSTM based names classification with a character-level model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBjjuHGrpDET"
   },
   "source": [
    "### 2.A. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "352Hw99iov92",
    "outputId": "328919f3-dae6-4738-bc6a-882034c7a151"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpNn9zocov9-",
    "outputId": "e1846783-437a-4acf-c1d4-09cac67a59e1"
   },
   "outputs": [],
   "source": [
    "print(category_lines['Italian'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89mLMqJoov9-"
   },
   "outputs": [],
   "source": [
    "names_data = []\n",
    "max_length = 0\n",
    "for category in category_lines.keys():\n",
    "    lengths = [len(x) for x in category_lines[category]]\n",
    "    if np.max(lengths)> max_length:\n",
    "        max_length = np.max(lengths)\n",
    "    names_data += [[x, category] for x in category_lines[category]]\n",
    "    \n",
    "print(names_data[:5])\n",
    "print(\"Names' maximum length =\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9ZKQggjov9-",
    "outputId": "87a5b982-edf3-4036-9ff7-e2da309ae1ac"
   },
   "outputs": [],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <max_length x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line, max_length=100):\n",
    "    tensor = torch.zeros(max_length, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones', max_length=max_length).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRfbG7IVov9_"
   },
   "outputs": [],
   "source": [
    "class NamesDataset(data.Dataset):\n",
    "    def __init__(self, names_data, max_length=100):\n",
    "        self.data = names_data\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        line, category = self.data[index]\n",
    "        category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "        line_tensor = lineToTensor(line, max_length = self.max_length)\n",
    "        return line_tensor, category_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3Uwq57vpSCO"
   },
   "source": [
    "### 2.B. Name Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOOhuVqcov9_"
   },
   "outputs": [],
   "source": [
    "# Define a RNN or LSTM model of your choice for names classification\n",
    "\n",
    "# *****START CODE\n",
    "class NameClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NameClassifier, self).__init__()\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return x\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dr_aazoJov9_",
    "outputId": "e8b2f879-859a-457a-96c3-3eb247419c61"
   },
   "outputs": [],
   "source": [
    "## Instantiate dataloader, optimizer, loss, and network\n",
    "\n",
    "n_hidden = 32\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "# *****START CODE\n",
    "random.shuffle(names_data)\n",
    "# define training dataset\n",
    "# define test dataset\n",
    "\n",
    "# define train loader\n",
    "# define test loader\n",
    "\n",
    "# instantiate your network\n",
    "# instantiate your optimizer\n",
    "# instantiate your loss\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Etz21Tg4ov9_",
    "outputId": "3a7cc3f2-3579-4b43-f78a-b86d07767a6a"
   },
   "outputs": [],
   "source": [
    "!pip install torchnet\n",
    "import torchnet as tnt\n",
    "\n",
    "# define confusion matrix using tnt package\n",
    "confusion_matrix = tnt.meter.ConfusionMeter(n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "obDp869Dov9_",
    "outputId": "51552d11-474e-4ba6-8689-b91dcb7880fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train your network\n",
    "\n",
    "# *****START CODE\n",
    "train_loss = []  \n",
    "test_loss = []\n",
    "for epoch in range(epochs):\n",
    "    running_train_loss = []   # variable to accumulate losses\n",
    "    running_test_loss = []\n",
    "    \n",
    "    # train loop\n",
    "    model.train()\n",
    "    for line_tensor_btch, category_tensor_batch in train_loader:\n",
    "    \n",
    "    # test loop\n",
    "    confusion_matrix.reset()\n",
    "    model.eval()\n",
    "    for line_tensor_btch, category_tensor_batch in test_loader:\n",
    "    \n",
    "    # print mean epoch loss and f1 score using accumulated loss and accumulated labels\n",
    "    print (f\"\\n###### Epoch {epoch} ######\")\n",
    "    train_loss.append(np.mean(running_train_loss))\n",
    "    print (\"Train Loss : \", np.mean(running_train_loss))\n",
    "    test_loss.append(np.mean(running_test_loss))    \n",
    "    print (\"Val Loss : \", np.mean(running_test_loss))\n",
    "    #print(\"Confusion Matrix:\")\n",
    "    #print(confusion_matrix.conf)\n",
    "    val_acc=(np.trace(confusion_matrix.conf)/float(np.ndarray.sum(confusion_matrix.conf))) *100\n",
    "    print (\"Val Acc : \", val_acc)\n",
    "# *****END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "szykFJCgov-A",
    "outputId": "c9633df1-cfd7-4730-fc37-c7329d9e202a"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "EzDYzRHiov-A",
    "outputId": "172f57fd-24b2-4294-faba-bc5c9880a891"
   },
   "outputs": [],
   "source": [
    "confusion = confusion_matrix.conf\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion, cmap=plt.get_cmap('cividis'), vmax=50)\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2uES4xpov-A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FDL_Lab06_solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
