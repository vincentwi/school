{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"DL_LAB_1.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"JNx-DlWhUojN"},"source":["# Deep Learning Course: Lab Exercises"]},{"cell_type":"markdown","metadata":{"id":"sfmNFn5pUojN"},"source":["In this lab exercise you will become familiar with the PyTorch library in order to solve deep learning problems. The goals of this assignments are as follows:\n","\n","- familiarize with PyTorch Tensors\n","\n","- understand how feedforward backpropagation works in neural networks\n"]},{"cell_type":"markdown","metadata":{"id":"h4j7Gf5LUojO"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"efuanY_UUojO"},"source":["For this exercise the only thing you need is this notebook."]},{"cell_type":"markdown","metadata":{"id":"pZumXYTYUojO"},"source":["# Note"]},{"cell_type":"markdown","metadata":{"id":"P-6WBdq3UojO"},"source":["Apart from the Questions, there are instruction comments throughout the notebook as well as comments inside the code cells beginning with two hashtags (##). In addition, there are #**START CODE  /  #**END CODE comments indicating the start and end of your code sections. Pay attention not to delete these comments."]},{"cell_type":"markdown","metadata":{"id":"_YQ2FNeqUojP"},"source":["# Questions"]},{"cell_type":"markdown","metadata":{"id":"-2LYwZGKUojP"},"source":["# Q1 - PyTorch Tensors"]},{"cell_type":"markdown","metadata":{"id":"aOus3aXGUojP"},"source":["a) Get familiar with PyTorch Tensors and construct different types of them."]},{"cell_type":"code","metadata":{"id":"g95S8R61UojP"},"source":["import torch\n","\n","##Construct a 5x3 matrix, uninitialized\n","# *****START CODE\n","x = \n","# *****END CODE\n","print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkCzwPzxUojQ"},"source":["##Construct a randomly initialized matrix from a normal distribution\n","# *****START CODE\n","\n","x = \n","# *****END CODE\n","print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pe99pXJHUojQ"},"source":["##Construct a matrix filled with zeros and of dtype int64\n","# *****START CODE\n","\n","x = \n","# *****END CODE\n","print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R43-VxQ6UojQ"},"source":["##Construct a tensor directly from data\n","# *****START CODE\n","\n","x = \n","# *****END CODE\n","print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UORgptIYUojR"},"source":["#Q2 Backpropagation from scratch\n","\n","- Create random input and output PyTorch tensors and train a simple network from scratch.\n","\n","  Warning: You should NOT use any forward/backward commands from PyTorch             library."]},{"cell_type":"code","metadata":{"id":"QtrAESF-UojR"},"source":["import torch.nn.functional as F\n","\n","## N is batch size; D_in is input dimension\n","## H is hidden dimenion; D_out is output dimension\n","\n","N, D_in, H, D_out = 64, 1000, 100, 10\n","\n","## Create random input (x) and output (y) data\n","# *****START CODE\n","x = \n","y = \n","print('x', x.shape)\n","print('y', y.shape)\n","# *****END CODE\n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zofILGJ3VCBz"},"source":["##Randomly initialize weights from a normal distribution, skipping bias\n","##Hint: You need 2 weight tensors; one for the raw input tensor (x) and one for the hidden dimension\n","# *****START CODE\n","w1 = \n","w2 = \n","# *****END CODE\n","print('w1', w1.shape)\n","print('w2', w2.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sQA5kvXVLge"},"source":["##define the learning rate\n","learning_rate = 1e-6\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xgDIJGcVfnb"},"source":["First, implement the forward pass. Try to compute the predicted y_pred value."]},{"cell_type":"code","metadata":{"id":"OlQ0tMGsVQrz"},"source":["## Calculate the output of the hidden dimension\n","## Hint: make use of torch.matmul()\n","# *****START CODE\n","import torch.nn.functional as F\n","h =                 # output of the hidden dimension \n","# *****END CODE  \n","print('h', h.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NbtF0QtWA25"},"source":["## Pass the output of the hidden dimension to the ReLU activation function\n","# *****START CODE\n","h_relu =            # output of the ReLU function\n","# *****END CODE  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAMaSc7JWA-E"},"source":["## Calculate the final output of the network\n","# *****START CODE\n","y_pred =            # final output of the network\n","# *****END CODE\n","print('y_pred', y_pred.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6xHdnKovWvIk"},"source":["Calculate the loss."]},{"cell_type":"code","metadata":{"id":"usvfBgnWVQ4T"},"source":["## Compute loss\n","loss = ((y_pred - y) ** 2).mean()\n","print(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QklmgLMnW1k_"},"source":["Now, implement the backward pass.\n","You need to minimize the loss with respect to each weight using the chain rule of differentiation."]},{"cell_type":"code","metadata":{"id":"rOlsl-15W35z"},"source":["## Compute the gradient of w2 with respect to the loss\n","# *****START CODE\n","\n","\n","# *****END CODE\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVWLJdcwXF_C"},"source":["## Compute the gradient of w1 with respect to the loss (consider the derivative of ReLU equal to 1)\n","# *****START CODE\n","\n","\n","# *****END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdZx29tlXNUx"},"source":["## Update weights\n","# *****START CODE\n","\n","\n","# *****END CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DWDA8CZXU5p"},"source":["Repeat the above process for a number of epochs and notice how the value of the loss changes."]},{"cell_type":"code","metadata":{"id":"jWbfq-36XkRN"},"source":["##specify the number of epochs\n","# *****START CODE\n","epochs =\n","# *****END CODE\n","\n","for t in range(epochs):\n","  # *****START CODE\n","\n","\n","\n","\n","  # *****END CODE\n","\n","\n"],"execution_count":null,"outputs":[]}]}