{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jXZOwWQ0wvUd"},"outputs":[],"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Machine Learning in Network Science\n","Lab 2: Link prediction\n","\"\"\"\n","%matplotlib inline\n","import os\n","import networkx as nx\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.sparse import *\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import roc_auc_score, roc_curve, auc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXKOUCcMwvUi"},"outputs":[],"source":["# Read network files\n","karate = # \n","\n","facebook = # \n","nodes = max(nx.connected_components(facebook), key=len) \n","facebook = facebook.subgraph(nodes) # has several connected components\n","\n","# Choose a network\n","G = karate\n","print(\"The number of nodes: {}\".format(G.number_of_nodes()))\n","print(\"The number of edges: {}\".format(G.number_of_edges()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAWCtkrNwvUi"},"outputs":[],"source":["# Plot graph\n","plt.figure(figsize=(5,5))\n","\n","pos = nx.random_layout(G, seed=19)\n","nx.draw(G, with_labels=False,  pos = pos, node_size = 50, alpha = 0.6, width = 0.6)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"0jLyrLObwvUj"},"source":["# Unsupervised link prediction"]},{"cell_type":"markdown","metadata":{"id":"sNpTVkFTwvUk"},"source":["In this section, we adopt an unsupervised approach for the link prediction task. In particular, we implement various similarity metrics (seen in class) and use them to predict future edges. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lL0os_XfwvUl"},"outputs":[],"source":["def preferential_attachement(graph):\n","    PA = {}\n","    \n","    # Fill in the blanks\n","    \n","    return PA\n","    \n","preferential_attachement(graph)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IUyrLtdwvUl"},"outputs":[],"source":["def Jaccard(graph):\n","    Jaccard = {}\n","    \n","    # Fill in the blanks\n","    \n","    return Jaccard\n","\n","# Jaccard(G)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3vCdWiJwvUm"},"outputs":[],"source":["def AdamicAdar(graph):\n","    AdamicAdar = {}\n","    \n","    # Fill in the blanks\n","    \n","    return AdamicAdar\n","\n","# AdamicAdar(G)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtPJtZwcwvUm"},"outputs":[],"source":["def predict_edges(metric, k=10):\n","    \"\"\"\n","    param metric (dict): contains pairs of nodes as keys\n","                        and the similarity metric as value\n","    \"\"\"\n","    \n","    # Shuffle randomly the entries of the dictionnary \n","    # Fill in the blanks \n","\n","    # Retrieve and return top k most similar edges\n","    # Fill in the blanks \n","    \n","    return metric.items()\n","\n","predict_edges(cnc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NplQgvGswvUn"},"outputs":[],"source":["# Optional \n","\n","def evaluation(graph):\n","    \"\"\"\n","    Evaluate and compare performance of above approaches\n","    \"\"\"\n","    res_graph = graph.copy()\n","    k = int(0.2 * graph.number_of_edges()) # number of true edges to remove from the graph\n","\n","    # --- Positive samples (k true edges of the graph) ---\n","    # Fill in the blanks\n","\n","    # --- Apply each method defined above and calculate its accuracy ---\n","    methods = ['common_neighbours_centrality', 'Jaccard', 'AdamicAdar', 'preferential_attachement']\n","    \n","    for method in methods: \n","        # Fill in the blanks\n","        accuracy = #\n","        print(method, accuracy)\n","\n","evaluation(G)"]},{"cell_type":"markdown","metadata":{"id":"ZEUzsZpFwvUn"},"source":["# Supervised link prediction"]},{"cell_type":"markdown","metadata":{"id":"fZLK7E2UwvUn"},"source":["In this section, we adopt a supervised approach for the link prediction task. We thus first pre-process the dataset so as to create labels for each edge, then derive a feature vector for each edge, before passing it to a traditional deep learning approach that classifies the edge into one of two categories. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YNORbYnywvUn"},"outputs":[],"source":["def generate_samples(graph, train_set_ratio):\n","    \"\"\"\n","    Graph pre-processing step required to perform supervised link prediction\n","    Create training and test sets\n","    \"\"\"\n","        \n","    # --- Step 0: The graph must be connected ---\n","    if nx.is_connected(G) is not True:\n","        raise ValueError(\"The graph contains more than one connected component!\")\n","       \n","    \n","    # --- Step 1: Generate positive edge samples for testing set ---\n","    residual_g = graph.copy()\n","    test_pos_samples = []\n","      \n","    # Shuffle the list of edges\n","    edges = list(residual_g.edges())\n","    np.random.shuffle(edges)\n","    \n","    # Define number of positive samples desired\n","    test_set_size = int((1.0 - train_set_ratio) * graph.number_of_edges())\n","    num_of_pos_test_samples = 0\n","    \n","    # Remove random edges from the graph, leaving it connected\n","    # Fill in the blanks\n","\n","    # Check if we have the desired number of positive samples for testing set \n","    if num_of_pos_test_samples != test_set_size:\n","        raise ValueError(\"Enough positive edge samples could not be found!\")\n","\n","        \n","    # --- Step 2: Generate positive edge samples for training set ---\n","    # The remaining edges are simply considered for positive samples of the training set\n","    train_pos_samples = list(residual_g.edges())\n","        \n","        \n","    # --- Step 3: Generate the negative samples for testing and training sets ---\n","    # Fill in the blanks\n","\n","    train_neg_samples = #\n","    test_neg_samples = #\n","\n","    \n","    # --- Step 4: Combine sample lists and create corresponding labels ---\n","    # For training set\n","    train_samples = train_pos_samples + train_neg_samples\n","    train_labels = [1 for _ in train_pos_samples] + [0 for _ in train_neg_samples]\n","    # For testing set\n","    test_samples = test_pos_samples + test_neg_samples\n","    test_labels = [1 for _ in test_pos_samples] + [0 for _ in test_neg_samples]\n","    \n","    return residual_g, train_samples, train_labels, test_samples, test_labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDLzyBt-wvUo"},"outputs":[],"source":["def feature_extractor(graph, samples):\n","    \"\"\"\n","    Creates a feature vector for each edge of the graph contained in samples \n","    \"\"\"\n","    feature_vector = [] \n","    \n","    # --- Extract manually diverse features relative to each edge contained in samples --- \n","    # Fill in the blanks\n","    \n","    # Degree Centrality measure\n","    deg_centrality = nx.degree_centrality(graph)\n","    \n","    # Betweeness centrality measure\n","    betweeness_centrality = nx.betweenness_centrality(graph)\n","\n","    for edge in tqdm(samples):\n","        source_node, target_node = edge[0], edge[1]\n","\n","        # Degree Centrality\n","        source_degree_centrality = #\n","        target_degree_centrality = #\n","        \n","        # Betweeness centrality  \n","        diff_bt = #\n","\n","        # Preferential Attachement \n","        pref_attach = list(nx.preferential_attachment(graph, [(source_node, target_node)]))[0][2]\n","\n","        # AdamicAdar\n","        aai = #\n","\n","        # Jaccard\n","        jacard_coeff = #\n","        \n","        # Create edge feature vector with all metric computed above\n","        feature_vector.append(np.array([source_degree_centrality, target_degree_centrality, \n","                                        diff_bt, pref_attach, aai, jacard_coeff]) ) \n","        \n","    return feature_vector"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Hz3AwwKwvUp"},"outputs":[],"source":["def prediction(graph, train_features, test_features, train_labels, test_labels):\n","    \"\"\"\n","    Downstream ML task using edge embeddings to classify them \n","    \"\"\"\n","    \n","    # --- Build the model and train it ---\n","    # Fill in the blanks\n","    \n","    train_preds = #\n","    test_preds = #\n","\n","    # --- Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from predictions ---\n","    # Fill in the blanks\n","    fpr, tpr, _ = #\n","    roc_auc = #\n","    \n","    plt.figure(figsize=(6,6))\n","    plt.plot(fpr, tpr, color='darkred', label='ROC curve (area = %0.3f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='lightgray', linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic Curve')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","    \n","    return roc_auc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gNTswHywvUp"},"outputs":[],"source":["# --- Construct the training and testing sets ---\n","residual_g, train_samples, train_labels, test_samples, test_labels = generate_samples(graph=G, train_set_ratio=0.8)\n","\n","# --- Create feature vector for all edges in training set and test set ---\n","train_features = feature_extractor(G, train_samples)\n","test_features = feature_extractor(G, test_samples)\n","\n","# --- Link prediction ---\n","prediction(G, train_features, test_features, train_labels, test_labels)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Lab2-Link-prediction.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}