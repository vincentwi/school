{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLNS Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of GraphSAGE\n",
        "\n",
        "Vincent Wilmet \\\n",
        "rmbr to use GPU"
      ],
      "metadata": {
        "id": "CQGXjmI1Dw_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import torch\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh4eth7F96tP",
        "outputId": "5c6c981e-1157-408b-a285-5d510607d529"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 25.4 GB  | Proc size: 1.2 GB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### init"
      ],
      "metadata": {
        "id": "4cE3oTR9PQVe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3DGckHw9DigE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301d2dcd-5074-45b8-f3c4-80336adfe6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.5)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-_yz0qspo\n",
            "  Running command git clone -q https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-_yz0qspo\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.5) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.5) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.5) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.5) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.5) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.5) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.5) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric==2.0.5) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.5) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.0.5) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.0.5) (1.1.0)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.63.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (0.2.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.10.0+cu111)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.21.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.63.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.5.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install ogb\n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjTcZZEjFc1F",
        "outputId": "c94de15b-ae59-4c98-d9e3-4b3d0be8fe45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kt-daBYHIQc",
        "outputId": "7af204d2-bdab-4791-9bed-a7d32775c203"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.loader import NeighborSampler\n",
        "from torch_geometric.nn import SAGEConv, GCNConv, GATConv, LEConv, GATv2Conv\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "from pandas.core.common import flatten"
      ],
      "metadata": {
        "id": "aMZK9GkzEd2T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n",
        "<b>Dataset</b>: We use [obgn-products](https://ogb.stanford.edu/docs/nodeprop/#ogbn-products) dataset which is an undirected and unweighted graph, representing an Amazon product co-purchasing network. Nodes represent products sold in Amazon, and edges between two products indicate that the products are purchased together. Node features represent bag-of-words features taken from the product descriptions. The goal is to predict the category of a product in a multi-class classification setup, where the 47 top-level categories are used for target labels making it a <b>Node Classification Task</b>. "
      ],
      "metadata": {
        "id": "-oYKleUWETBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "from pandas.core.common import flatten\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(rc={'figure.figsize':(16.7,8.27)})\n",
        "sns.set_theme(style=\"ticks\")\n",
        "import collections\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "id": "6zCuC9doEtiv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fp = '/content/drive/MyDrive/final_project/'\n",
        "dataset = PygNodePropPredDataset('ogbn-products', fp)"
      ],
      "metadata": {
        "id": "b6BRjEZEEv9C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split_idx contains a dictionary of train, validation and test node indices\n",
        "split_idx = dataset.get_idx_split()\n",
        "# predefined ogb evaluator method used for validation of predictions\n",
        "evaluator = Evaluator(name='ogbn-products')"
      ],
      "metadata": {
        "id": "d3DO9lEpE0Ym"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "Iurmhk8PEy6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of training nodes:', split_idx['train'].size(0))\n",
        "print('Number of validation nodes:', split_idx['valid'].size(0))\n",
        "print('Number of test nodes:', split_idx['test'].size(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycef-YMLE0Wr",
        "outputId": "1d6b2560-3e0a-4781-d62e-08c71efb2c3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training nodes: 196615\n",
            "Number of validation nodes: 39323\n",
            "Number of test nodes: 2213091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "qtvjPnTXE0Uf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic graph statistics of ogb-product graph\n",
        "print(\"Number of nodes in the graph:\", data.num_nodes)\n",
        "print(\"Number of edges in the graph:\", data.num_edges)\n",
        "print(\"Node feature matrix with shape:\", data.x.shape) # [num_nodes, num_node_features]\n",
        "print(\"Graph connectivity in COO format with shape:\", data.edge_index.shape) # [2, num_edges]\n",
        "print(\"Target to train against :\", data.y.shape) \n",
        "print(\"Node feature length\", dataset.num_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUCn9ZgbE0SQ",
        "outputId": "878aa59a-95a6-4c03-8004-79d70d8afafe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes in the graph: 2449029\n",
            "Number of edges in the graph: 123718280\n",
            "Node feature matrix with shape: torch.Size([2449029, 100])\n",
            "Graph connectivity in COO format with shape: torch.Size([2, 123718280])\n",
            "Target to train against : torch.Size([2449029, 1])\n",
            "Node feature length 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# there are indeed 47 unique categories of product, as expected\n",
        "data.y.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0fCn1glE0QC",
        "outputId": "505a6de7-a3a2-4952-d704-ff1f5128c88f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
              "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train_loader\n",
        "`train_loader` computes the k-hop neighborhood of a batch of nodes, and returns, for each layer, a bipartite graph object, holding the bipartite edges `edge_index`, the index `e_id` of the original edges, and the size/shape `size` of the bipartite graph.\n",
        "\n",
        "Here we are sampling 20 one-hop neighbours, 15 two-hop neighbours and 10 three-hop neighbours."
      ],
      "metadata": {
        "id": "VN4dGDR6OJ9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx = split_idx['train']\n",
        "train_loader = NeighborSampler(data.edge_index, node_idx=train_idx,\n",
        "                               sizes=[20, 15, 10], batch_size=256,\n",
        "                               shuffle=True)"
      ],
      "metadata": {
        "id": "IkhQQ23KKuzI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading"
      ],
      "metadata": {
        "id": "trVNVlrLGmdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load integer to real product category from label mapping provided inside the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/final_project/ogbn_products/mapping/labelidx2productcategory.csv.gz')"
      ],
      "metadata": {
        "id": "FboRaOFXGK8t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dictionary of product category and corresponding integer label\n",
        "label_idx, prod_cat = df.iloc[: ,0].values, df.iloc[: ,1].values\n",
        "label_mapping = dict(zip(label_idx, prod_cat))\n",
        "print(\"Label mapping\", label_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uDerStZGc-E",
        "outputId": "79cee6f0-171e-40d0-c81d-b99f3daa411b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping {0: 'Home & Kitchen', 1: 'Health & Personal Care', 2: 'Beauty', 3: 'Sports & Outdoors', 4: 'Books', 5: 'Patio, Lawn & Garden', 6: 'Toys & Games', 7: 'CDs & Vinyl', 8: 'Cell Phones & Accessories', 9: 'Grocery & Gourmet Food', 10: 'Arts, Crafts & Sewing', 11: 'Clothing, Shoes & Jewelry', 12: 'Electronics', 13: 'Movies & TV', 14: 'Software', 15: 'Video Games', 16: 'Automotive', 17: 'Pet Supplies', 18: 'Office Products', 19: 'Industrial & Scientific', 20: 'Musical Instruments', 21: 'Tools & Home Improvement', 22: 'Magazine Subscriptions', 23: 'Baby Products', 24: nan, 25: 'Appliances', 26: 'Kitchen & Dining', 27: 'Collectibles & Fine Art', 28: 'All Beauty', 29: 'Luxury Beauty', 30: 'Amazon Fashion', 31: 'Computers', 32: 'All Electronics', 33: 'Purchase Circles', 34: 'MP3 Players & Accessories', 35: 'Gift Cards', 36: 'Office & School Supplies', 37: 'Home Improvement', 38: 'Camera & Photo', 39: 'GPS & Navigation', 40: 'Digital Music', 41: 'Car Electronics', 42: 'Baby', 43: 'Kindle Store', 44: 'Buy a Kindle', 45: 'Furniture & D&#233;cor', 46: '#508510'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data.y.tolist()\n",
        "y = list(flatten(y))\n",
        "count_y = collections.Counter(y)\n",
        "print(count_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj0xRw22Ger4",
        "outputId": "ecf40575-9e6f-4caf-e154-92fa522640ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({4: 668950, 7: 172199, 6: 158771, 3: 151061, 12: 131886, 2: 116043, 0: 114294, 8: 110796, 1: 109832, 13: 101541, 16: 83594, 21: 80795, 9: 67358, 10: 52345, 18: 49019, 24: 45406, 17: 42337, 5: 40715, 11: 32937, 42: 32500, 15: 26911, 20: 22575, 19: 17438, 23: 3653, 14: 3079, 25: 3024, 28: 1969, 29: 1561, 43: 1399, 22: 879, 36: 630, 44: 566, 26: 553, 37: 514, 32: 513, 31: 418, 30: 277, 27: 259, 34: 154, 38: 91, 41: 61, 35: 44, 39: 37, 33: 29, 45: 9, 40: 6, 46: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.x.to(device)\n",
        "y = data.y.squeeze().to(device)"
      ],
      "metadata": {
        "id": "fkBiv2d3IffO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "RED623feEVlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            xs = []\n",
        "            x_target = x[:size[1]]\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=0.25, training=self.training)\n",
        "            xs.append(x)\n",
        "            if i == 0: \n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all    \n",
        "        return layer_3_embeddings.log_softmax(dim=-1)\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "        total_edges = 0\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in test_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                total_edges += edge_index.size(1)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = F.relu(x)\n",
        "                xs.append(x)\n",
        "                pbar.update(batch_size)\n",
        "\n",
        "            if i == 0: \n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "        pbar.close()\n",
        "        return layer_3_embeddings.log_softmax(dim=-1)"
      ],
      "metadata": {
        "id": "kE56B1MBulX9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            xs = []\n",
        "            x_target = x[:size[1]]\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=0.25, training=self.training)\n",
        "            xs.append(x)\n",
        "            if i == 0: \n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all    \n",
        "        return layer_3_embeddings.log_softmax(dim=-1)\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "        total_edges = 0\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in test_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                total_edges += edge_index.size(1)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = F.relu(x)\n",
        "                xs.append(x)\n",
        "                pbar.update(batch_size)\n",
        "\n",
        "            if i == 0: \n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "        pbar.close()\n",
        "        return layer_3_embeddings.log_softmax(dim=-1)"
      ],
      "metadata": {
        "id": "Q2T3fAb-G_U4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 heads):\n",
        "        super(GAT, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GATConv(dataset.num_features, hidden_channels,\n",
        "                                  heads))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(\n",
        "                GATConv(heads * hidden_channels, hidden_channels, heads))\n",
        "        self.convs.append(\n",
        "            GATConv(heads * hidden_channels, out_channels, heads, concat=False))\n",
        "\n",
        "        self.skips = torch.nn.ModuleList()\n",
        "        self.skips.append(Linear(dataset.num_features, hidden_channels * heads))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.skips.append(\n",
        "                Linear(hidden_channels * heads, hidden_channels * heads))\n",
        "        self.skips.append(Linear(hidden_channels * heads, out_channels))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for skip in self.skips:\n",
        "            skip.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            x_target = x[:size[1]]\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.elu(x)\n",
        "                x = F.dropout(x, p=0.25, training=self.training)\n",
        "\n",
        "            x = x + self.skips[i](x_target)\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "        total_edges = 0\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in test_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                total_edges += edge_index.size(1)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = F.elu(x)\n",
        "                \n",
        "                x = x + self.skips[i](x_target)\n",
        "                xs.append(x.cpu())\n",
        "                pbar.update(batch_size)\n",
        "            x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "        pbar.close()\n",
        "        return x_all"
      ],
      "metadata": {
        "id": "YJ19idbT76cI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GATv2(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 heads):\n",
        "        super(GATv2, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GATv2Conv(dataset.num_features, hidden_channels,\n",
        "                                  heads))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(\n",
        "                GATv2Conv(heads * hidden_channels, hidden_channels, heads))\n",
        "        self.convs.append(\n",
        "            GATv2Conv(heads * hidden_channels, out_channels, heads, concat=False))\n",
        "\n",
        "        self.skips = torch.nn.ModuleList()\n",
        "        self.skips.append(Linear(dataset.num_features, hidden_channels * heads))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.skips.append(\n",
        "                Linear(hidden_channels * heads, hidden_channels * heads))\n",
        "        self.skips.append(Linear(hidden_channels * heads, out_channels))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for skip in self.skips:\n",
        "            skip.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            x_target = x[:size[1]]\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.elu(x)\n",
        "                x = F.dropout(x, p=0.25, training=self.training)\n",
        "\n",
        "            x = x + self.skips[i](x_target)\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "        total_edges = 0\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in test_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                total_edges += edge_index.size(1)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = F.elu(x)\n",
        "                \n",
        "                x = x + self.skips[i](x_target)\n",
        "                xs.append(x.cpu())\n",
        "                pbar.update(batch_size)\n",
        "            x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "        pbar.close()\n",
        "        return x_all"
      ],
      "metadata": {
        "id": "xjkmuk99qBqe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeGCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
        "        super(LeGCN, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(LEConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(LEConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(LEConv(hidden_channels, out_channels))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            xs = []\n",
        "            x_target = x[:size[1]]\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=0.25, training=self.training)\n",
        "            xs.append(x)\n",
        "            if i == 0: \n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all    \n",
        "        return layer_3_embeddings.log_softmax(dim=-1)\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "        total_edges = 0\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in test_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                total_edges += edge_index.size(1)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = F.relu(x)\n",
        "                xs.append(x)\n",
        "                pbar.update(batch_size)\n",
        "            if i == 0: \n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "        pbar.close()\n",
        "        return layer_3_embeddings.log_softmax(dim=-1)"
      ],
      "metadata": {
        "id": "wC40dPLYafOZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop\n",
        "\n",
        "While using test_loader for evaluation, we should delete the train_loader. Otherwise, Google Colab is crashing due to memory limitation."
      ],
      "metadata": {
        "id": "4JXSI71HHXbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "\n",
        "    pbar = tqdm(total=train_idx.size(0))\n",
        "    pbar.set_description(f'Epoch {epoch:02d}')\n",
        "\n",
        "    total_loss = total_correct = 0\n",
        "    for batch_size, n_id, adjs in train_loader:\n",
        "        adjs = [adj.to(device) for adj in adjs]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x[n_id], adjs)\n",
        "        loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())\n",
        "        pbar.update(batch_size)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    loss = total_loss / len(train_loader)\n",
        "    approx_acc = total_correct / train_idx.size(0)\n",
        "    return loss, approx_acc"
      ],
      "metadata": {
        "id": "-S8qhrrOwS1I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = SAGE(in_channels=dataset.num_features, hidden_channels=256,\n",
        "            #  out_channels=dataset.num_classes, num_layers=3)\n",
        "\n",
        "# model = GCN(in_channels=dataset.num_features, hidden_channels=256,\n",
        "#             out_channels=dataset.num_classes, num_layers=3)\n",
        "\n",
        "# model = LeGCN(in_channels=dataset.num_features, hidden_channels=256, \n",
        "#               out_channels=dataset.num_classes, num_layers=3)\n",
        "\n",
        "# model = GAT(in_channels=dataset.num_features, hidden_channels=128,\n",
        "#               out_channels=dataset.num_classes, num_layers=4, heads=4)\n",
        "\n",
        "model = GATv2(in_channels=dataset.num_features, hidden_channels=128,\n",
        "              out_channels=dataset.num_classes, num_layers=4, heads=4)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "j3vS-HrJIYMI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.004)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    loss, acc = train(epoch)\n",
        "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDsH_2efjUZW",
        "outputId": "43cbb0fc-6885-4587-f1e2-8dd08979056d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 01: 100%|██████████| 196615/196615 [05:04<00:00, 645.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01, Loss: 0.4890, Approx. Train: 0.8714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 02: 100%|██████████| 196615/196615 [05:03<00:00, 647.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02, Loss: 0.3656, Approx. Train: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 03: 100%|██████████| 196615/196615 [05:04<00:00, 645.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03, Loss: 0.3413, Approx. Train: 0.9070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 04: 100%|██████████| 196615/196615 [05:04<00:00, 645.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04, Loss: 0.3339, Approx. Train: 0.9101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 05: 100%|██████████| 196615/196615 [05:03<00:00, 648.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05, Loss: 0.3302, Approx. Train: 0.9102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 06: 100%|██████████| 196615/196615 [05:03<00:00, 648.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06, Loss: 0.3222, Approx. Train: 0.9117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 07: 100%|██████████| 196615/196615 [05:01<00:00, 652.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07, Loss: 0.3127, Approx. Train: 0.9137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 08: 100%|██████████| 196615/196615 [05:03<00:00, 648.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08, Loss: 0.3145, Approx. Train: 0.9140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 09: 100%|██████████| 196615/196615 [05:04<00:00, 646.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09, Loss: 0.3091, Approx. Train: 0.9154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 196615/196615 [05:01<00:00, 651.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.3072, Approx. Train: 0.9157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 196615/196615 [05:02<00:00, 649.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 0.3067, Approx. Train: 0.9155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 196615/196615 [05:08<00:00, 636.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 0.3044, Approx. Train: 0.9164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 196615/196615 [05:09<00:00, 635.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 0.3047, Approx. Train: 0.9165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 196615/196615 [05:10<00:00, 634.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 0.3040, Approx. Train: 0.9172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 196615/196615 [05:09<00:00, 636.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 0.3047, Approx. Train: 0.9168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 196615/196615 [05:15<00:00, 622.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 0.3023, Approx. Train: 0.9177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 196615/196615 [05:19<00:00, 614.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 0.3037, Approx. Train: 0.9170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 196615/196615 [05:15<00:00, 623.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 0.3016, Approx. Train: 0.9179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 196615/196615 [05:29<00:00, 596.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 0.3013, Approx. Train: 0.9175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 196615/196615 [05:20<00:00, 613.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 0.2998, Approx. Train: 0.9178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function: negative log-likelihood.\n",
        "\n",
        "![Screenshot 2022-04-06 at 13.51.26.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "P3RsI1-LEIVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the model\n"
      ],
      "metadata": {
        "id": "wk9hM5hwJPRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving model in Google Drive\n",
        "MODEL_PATH = '/content/drive/MyDrive/final_project/models/model_GATv2.pt'\n",
        "torch.save(model, MODEL_PATH)\n",
        "print(f'Model Saved at {MODEL_PATH}')"
      ],
      "metadata": {
        "id": "ODzo6kTUJP6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59832655-5976-4121-87de-98b69a7aa377"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved at /content/drive/MyDrive/final_project/models/model_GATv2.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "HmXLr-PiwnTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model\n",
        "Computing the accuracies on the validation and test sets."
      ],
      "metadata": {
        "id": "1JkLvXsOLLFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = NeighborSampler(data.edge_index, node_idx=None,\n",
        "                              sizes=[-1], # all neighbours of a node\n",
        "                              batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "ID8Js6B1VyNG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the saved model\n",
        "model = torch.load(MODEL_PATH, map_location=torch.device(device))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "9_j04D1FME1z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_accuracy():\n",
        "    model.eval()\n",
        "    out = model.inference(x)\n",
        "    y_true = y.cpu().unsqueeze(-1)\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx[\"train\"]],\n",
        "        'y_pred': y_pred[split_idx[\"train\"]],\n",
        "    })['acc']\n",
        "\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx[\"valid\"]],\n",
        "        'y_pred': y_pred[split_idx[\"valid\"]],\n",
        "    })['acc']\n",
        "\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx[\"test\"]],\n",
        "        'y_pred': y_pred[split_idx[\"test\"]],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ],
      "metadata": {
        "id": "5KYTICxDNo-z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc, valid_acc, test_acc = compute_accuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AXJ9_umcJzs",
        "outputId": "d1af0a83-9065-451d-ea83-6b94d51a709d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 7347087/7347087 [01:58<00:00, 61869.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train accuracy:', np.round(train_acc*100, 2))\n",
        "print('Validation accuracy:', np.round(valid_acc*100, 2))\n",
        "print('Test accuracy:', np.round(test_acc*100, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCqCkjeLbwQF",
        "outputId": "60806023-29e6-4121-b46f-f4be39c99588"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 93.38\n",
            "Validation accuracy: 91.57\n",
            "Test accuracy: 84.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "\n",
        "\n",
        "1. [Inductive Representation Learning on Large Graphs](https://arxiv.org/pdf/1706.02216.pdf)\n",
        "\n",
        "2. http://web.stanford.edu/class/cs224w/slides/17-scalable.pdf\n",
        "\n",
        "3. [A Voyage through Graph Machine Learning Universe: Motivation, Applications, Datasets, Graph ML Libraries, Graph Databases](https://sachinsharma9780.medium.com/)\n",
        "\n",
        "3. https://medium.com/pinterest-engineering/pinsage-a-new-graph-convolutional-neural-network-for-web-scale-recommender-systems-88795a107f48\n",
        "\n",
        "4. https://eng.uber.com/uber-eats-graph-learning/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vFtLu86PRobR"
      }
    }
  ]
}