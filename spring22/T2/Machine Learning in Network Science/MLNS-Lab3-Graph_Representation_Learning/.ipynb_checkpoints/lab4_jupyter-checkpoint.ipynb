{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Machine Learning in Network Science\n",
    "Lab 3: Network representation learning\n",
    "March 19, 2021\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "from helper import *\n",
    "import os\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from node2vec import Node2Vec\n",
    "from scipy.sparse import *\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes: 34\n",
      "The number of edges: 78\n"
     ]
    }
   ],
   "source": [
    "# Read network files\n",
    "G = nx.read_gml(\"karate.gml\")\n",
    "\n",
    "print(\"The number of nodes: {}\".format(G.number_of_nodes()))\n",
    "print(\"The number of edges: {}\".format(G.number_of_edges()))\n",
    "\n",
    "# Get the node community labels and the number of communities\n",
    "node2comm, num_of_communities = get_node2community(g=G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Network Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1: Implementation of a random walking strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_walks(graph, N, L):\n",
    "    '''\n",
    "    :param graph: networkx graph\n",
    "    :param N: the number of walks for each node\n",
    "    :param L: the walk length\n",
    "    :return walks: the list of walks\n",
    "    '''\n",
    "    walks = []\n",
    "\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "        \n",
    "    return walks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2: Learning representations of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_walks=\n",
    "walk_length=\n",
    "embedding_size = \n",
    "window_size = \n",
    "output_filename=\"./graph.embedding\"\n",
    "\n",
    "# Perform random walks - call function\n",
    "walks = #\n",
    "# Learn representations of nodes - use Word2Vec\n",
    "model = #\n",
    "# Save the embedding vectors\n",
    "model.wv.save_word2vec_format(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise embeddings\n",
    "visualize(graph=G, node2embedding=model.wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Link Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions seen in previous lab - Nothing to do\n",
    "\n",
    "def generate_samples(graph, train_set_ratio):\n",
    "    \"\"\"\n",
    "    Graph pre-processing step required to perform supervised link prediction\n",
    "    Create training and test sets\n",
    "    \"\"\"\n",
    "        \n",
    "    # --- Step 0: The graph must be connected ---\n",
    "    if nx.is_connected(G) is not True:\n",
    "        raise ValueError(\"The graph contains more than one connected component!\")\n",
    "       \n",
    "    \n",
    "    # --- Step 1: Generate positive edge samples for testing set ---\n",
    "    residual_g = graph.copy()\n",
    "    test_pos_samples = []\n",
    "      \n",
    "    # Store the shuffled list of current edges of the graph\n",
    "    edges = list(residual_g.edges())\n",
    "    np.random.shuffle(edges)\n",
    "    \n",
    "    # Define number of positive test samples desired\n",
    "    test_set_size = int((1.0 - train_set_ratio) * graph.number_of_edges())\n",
    "    train_set_size = graph.number_of_edges() - test_set_size\n",
    "    num_of_pos_test_samples = 0\n",
    "    \n",
    "    # Remove random edges from the graph, leaving it connected\n",
    "    for edge in edges:\n",
    "        \n",
    "        # Remove the edge\n",
    "        residual_g.remove_edge(edge[0], edge[1])\n",
    "        \n",
    "        # Add the removed edge to the positive sample list if the network is still connected\n",
    "        if nx.is_connected(residual_g):\n",
    "            num_of_pos_test_samples += 1\n",
    "            test_pos_samples.append(edge)\n",
    "        # Otherwise, re-add the edge to the network\n",
    "        else: \n",
    "            residual_g.add_edge(edge[0], edge[1])\n",
    "        \n",
    "        # If we have collected enough number of edges for testing set, we can terminate the loop\n",
    "        if num_of_pos_test_samples == test_set_size:\n",
    "            break\n",
    "    \n",
    "    # Check if we have the desired number of positive samples for testing set \n",
    "    if num_of_pos_test_samples != test_set_size:\n",
    "        raise ValueError(\"Enough positive edge samples could not be found!\")\n",
    "\n",
    "        \n",
    "    # --- Step 2: Generate positive edge samples for training set ---\n",
    "    # The remaining edges are simply considered for positive samples of the training set\n",
    "    train_pos_samples = list(residual_g.edges())\n",
    "        \n",
    "        \n",
    "    # --- Step 3: Generate the negative samples for testing and training sets ---\n",
    "    non_edges = list(nx.non_edges(graph))\n",
    "    np.random.shuffle(non_edges)\n",
    "    \n",
    "    train_neg_samples = non_edges[:train_set_size] \n",
    "    test_neg_samples = non_edges[train_set_size:train_set_size + test_set_size]\n",
    "\n",
    "    \n",
    "    # --- Step 4: Combine sample lists and create corresponding labels ---\n",
    "    # For training set\n",
    "    train_samples = train_pos_samples + train_neg_samples\n",
    "    train_labels = [1 for _ in train_pos_samples] + [0 for _ in train_neg_samples]\n",
    "    # For testing set\n",
    "    test_samples = test_pos_samples + test_neg_samples\n",
    "    test_labels = [1 for _ in test_pos_samples] + [0 for _ in test_neg_samples]\n",
    "    \n",
    "    return residual_g, train_samples, train_labels, test_samples, test_labels\n",
    "\n",
    "\n",
    "def edge_prediction(node2embedding, train_samples, test_samples, train_labels, test_labels, feature_func=None):\n",
    "    \n",
    "    # --- Construct feature vectors for edges ---\n",
    "    if feature_func is None:\n",
    "        feature_func = lambda x,y: abs(x-y)\n",
    "    \n",
    "    train_features = [feature_func(node2embedding[edge[0]], node2embedding[edge[1]]) for edge in train_samples]\n",
    "    test_features = [feature_func(node2embedding[edge[0]], node2embedding[edge[1]]) for edge in test_samples]\n",
    "    \n",
    "    # --- Build the model and train it ---\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    train_preds = clf.predict_proba(train_features)[:, 1]\n",
    "    test_preds = clf.predict_proba(test_features)[:, 1]\n",
    "\n",
    "    # --- Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from predictions ---\n",
    "    fpr, tpr, _ = roc_curve(test_labels, test_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, color='darkred', label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='lightgray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data - construct training and testing sets \n",
    "\n",
    "# Perform random walks over the residual network\n",
    "\n",
    "# Learn representations of nodes\n",
    "\n",
    "# Perform the edge prediction and plot the ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but using Node2Vec instead of Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Node Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_classif(graph, node2embedding, train_set_ratio): \n",
    "    \"\"\"Perform node classification on graph \n",
    "    \n",
    "    args node2embedding: dictionnary of node embedding\n",
    "    args return: accuracy score \n",
    "    \"\"\"\n",
    "\n",
    "    # Get the ground-truth labels \n",
    "    node2community, K = get_node2community(G)\n",
    "\n",
    "    # Create feature matrix (np.array)\n",
    "    x = # \n",
    "    # Create label matrix \n",
    "    labels = # \n",
    "\n",
    "    # Get the training size\n",
    "    train_set_size = #\n",
    "\n",
    "    # Shuffle the data\n",
    "    shuffled_features, shuffled_labels = shuffle(x, labels)\n",
    "\n",
    "    # Divide the data into the training and test sets\n",
    "    train_features = shuffled_features[0:train_set_size, :]\n",
    "    train_labels = shuffled_labels[0:train_set_size]\n",
    "\n",
    "    test_features = #\n",
    "    test_labels = #\n",
    "\n",
    "    # Build the model and train it\n",
    "    clf = OneVsRestClassifier(LogisticRegression())\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    # Find the predictions, each node can have multiple labels\n",
    "    test_prob = #\n",
    "    y_pred = # careful to format for accuracy score\n",
    "\n",
    "\n",
    "    return accuracy_score(test_labels, y_pred)\n",
    "\n",
    "node_classif(graph, model.wv, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the facebook page-page network, also contained in the folder downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph\n",
    "\n",
    "# Import labels \n",
    "\n",
    "# Pre-process labels (Categorical variables are not desirable - Want multiple dummies instead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
