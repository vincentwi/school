{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-colombia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:30.994336Z",
     "start_time": "2022-06-09T07:14:22.718885Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax.scipy.stats.multivariate_normal import logpdf as jlogpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-wyoming",
   "metadata": {},
   "source": [
    "# Question 1: Reading and formatting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-anatomy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:31.103774Z",
     "start_time": "2022-06-09T07:14:30.998729Z"
    }
   },
   "outputs": [],
   "source": [
    "#1.1 : Read the datset with pandas\n",
    "dataset = pd.read_csv(\"GermanCredit.txt\", sep =\"\\s+\", header=None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-accounting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:31.165105Z",
     "start_time": "2022-06-09T07:14:31.112893Z"
    }
   },
   "outputs": [],
   "source": [
    "#1.2 : Creating ytrain. For convenience, we will use 0 and 1 as labels\n",
    "dataset[24] = dataset[24] - 1\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-discussion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:31.264700Z",
     "start_time": "2022-06-09T07:14:31.182019Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1.2 Split into train and test set\n",
    "M = 800 # train set size\n",
    "d = 24\n",
    "length = dataset.shape[0]\n",
    "y_train = dataset.loc[:M-1, d]\n",
    "y_test = dataset.loc[M:, d]\n",
    "\n",
    "x_train = dataset.loc[:M-1, :d-1]\n",
    "x_test = dataset.loc[M:, :d-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-natural",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:31.589580Z",
     "start_time": "2022-06-09T07:14:31.290540Z"
    }
   },
   "outputs": [],
   "source": [
    "#1.3 Center and scale the features\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-setting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:31.640839Z",
     "start_time": "2022-06-09T07:14:31.592390Z"
    }
   },
   "outputs": [],
   "source": [
    "#1.3 : scaling xtrain \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-galaxy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:33.164243Z",
     "start_time": "2022-06-09T07:14:31.646173Z"
    }
   },
   "outputs": [],
   "source": [
    "#1.4 Extend them with a column of ones, which is for logistic regression\n",
    "ones_train = jnp.ones((M, 1))\n",
    "ones_test = jnp.ones((length-M, 1))\n",
    "x_train = jnp.concatenate((ones_train, x_train), axis=1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-ridge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:33.274230Z",
     "start_time": "2022-06-09T07:14:33.177832Z"
    }
   },
   "outputs": [],
   "source": [
    "# the shape changes to dimension 25\n",
    "x_test = jnp.concatenate((ones_test, x_test), axis=1)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-burning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:33.715125Z",
     "start_time": "2022-06-09T07:14:33.285253Z"
    }
   },
   "outputs": [],
   "source": [
    "#make sure that the values are scaled \n",
    "jnp.mean(x_train, axis=0), jnp.std(x_train, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-novel",
   "metadata": {},
   "source": [
    "# Question 2: Model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-network",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:33.736487Z",
     "start_time": "2022-06-09T07:14:33.728079Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "##### 2.1 : Proof of log-odds ratio\n",
    "Let us denote $$z= \\beta_0 + \\sum_{j = 1}^n \\beta_j X_j.$$\n",
    "\n",
    "We are to show that\n",
    "$$ \\log \\frac{P(Y=1|\\beta)}{1-P(Y=1|\\beta)} = z.$$\n",
    "We can rewrite the left hand side by splitting the fraction of the log\n",
    "\\begin{align*} \n",
    "\\log \\frac{P(Y=1|\\beta)}{1-P(Y=1|\\beta)} &=  \\log \\frac{1}{1+e^{-z}} - \\log \\frac{e^{-z}}{1+e^{-z}}\\\\ \n",
    " &=   \\log 1 - \\log e^{-z}\\\\ \n",
    " &=  - \\log e^{-z}\\\\ \n",
    " &= z\n",
    "\\end{align*}\n",
    "Note that in the second step we used that you can split again to 4 logarithms and then the log of the denominators will have opposite sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-access",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:33.751529Z",
     "start_time": "2022-06-09T07:14:33.745122Z"
    }
   },
   "outputs": [],
   "source": [
    "##### 2.2 : Parameters\n",
    "We can interepret these parameters as XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-irish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:33.779556Z",
     "start_time": "2022-06-09T07:14:33.764114Z"
    }
   },
   "outputs": [],
   "source": [
    "#2.3 : Decision Boundry. is it in terms of prob or vars >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-traffic",
   "metadata": {},
   "source": [
    "##### 2.4 : Proof of log-likelihood\n",
    "Let us denote $$z_i= \\beta_0 + \\sum_{j = 1}^n \\beta_j X_{i,j}.$$\n",
    "\n",
    "If $y_i = 1$, we see that the right hand side is \n",
    "\\begin{align*} \n",
    "\\log \\frac{1}{1+e^{-z_i}}  &= \\log \\frac{e^z_i}{1+e^{z_i}}\\\\\n",
    "&= z_i - \\log 1+e^z_i\\\\\n",
    "&= y_i z_i - \\log 1+e^z_i.\n",
    "\\end{align*}\n",
    "\n",
    "If $y_i = 0$, we see that the right hand side is \n",
    "\\begin{align*} \n",
    "\\log \\frac{e^{-z_i}}{1+e^{-z_i}}  &= \\log \\frac{1}{1+e^{z_i}}\\\\\n",
    "&= 0 - \\log 1+e^{z_i}\\\\\n",
    "&= y_i z_i - \\log 1+e^{z_i}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation – never used\n",
    "def log_likelihood(beta):\n",
    "    x_beta = np.matmul(x_train, beta)\n",
    "    output = np.sum(y_train * x_beta - np.log(1 + np.exp(x_beta)))\n",
    "    return output\n",
    "\n",
    "math needed: Is there an error?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-mexico",
   "metadata": {},
   "source": [
    "##### 2.5 : Jax-compatible log-likelihood\n",
    "\n",
    "We are asked to calculate\n",
    "$$\\log P(y_1,...,y_m| \\beta).$$\n",
    "\n",
    "By independence of the training data points, this equals\n",
    "$$\\log \\prod_{i=1}^m P(y_i| \\beta).$$\n",
    "\n",
    "We can now use the result from previous exercise to see that \n",
    "\n",
    "\\begin{align*} \n",
    "\\log \\prod_{i=1}^m P(y_i| \\beta) &=  \\sum_{i=1}^m \\log P(y_i| \\beta) \\\\\n",
    "&= \\sum_{i=1}^m (y_i z_i - \\log 1+e^z_i)\\\\\n",
    "&= \\sum_{i=1}^m y_i z_i -  \\sum_{i=1}^m \\log 1+e^z_i.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#math and speed comparison needed\n",
    "@jit\n",
    "def log_likelihood_jax(beta):\n",
    "    x_beta = jnp.matmul(x_train, beta)\n",
    "    output = jnp.sum(y_train * x_beta - jnp.log(1 + jnp.exp(x_beta)))\n",
    "    return output\n",
    "\n",
    "# After investigation, the jit implementations speeds up significantly\n",
    "jit_likelihood_jax = jit(log_likelihood_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-wrestling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:14:33.848809Z",
     "start_time": "2022-06-09T07:14:33.839386Z"
    }
   },
   "outputs": [],
   "source": [
    "#2.6 : Gradient\n",
    "# speed comparison needed\n",
    "\n",
    "# Evaluates the gradient of the log likelihood for any beta\n",
    "# After investigation, the jit implementations speeds up significantly\n",
    "grad_log_likelihood = jit(grad(log_likelihood_jax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-leone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:25:05.295090Z",
     "start_time": "2022-06-09T07:25:04.961229Z"
    }
   },
   "outputs": [],
   "source": [
    "#2.7 : Logprior Function\n",
    "#speed comparison is needed\n",
    "\n",
    "DIM = 25\n",
    "constant = np.pi**2 * M / (3*DIM)\n",
    "Sigma = constant * np.linalg.inv(np.matmul(x_train.T, x_train))\n",
    "\n",
    "@jit\n",
    "def log_prior(beta):\n",
    "    '''\n",
    "    Input – beta: a vector of size d+1\n",
    "    Output – log prior density: constant\n",
    "    '''\n",
    "    return jlogpdf(beta, mean = jnp.zeros(DIM), cov = Sigma)\n",
    "\n",
    "\n",
    "# After investigation, the jit implementations does not speed up significantly\n",
    "# jitlogprior = jit(logprior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-disability",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:25:07.218597Z",
     "start_time": "2022-06-09T07:25:07.178685Z"
    }
   },
   "outputs": [],
   "source": [
    "#2.8 : Gradient\n",
    "#speed comparison is needed\n",
    "grad_log_prior = jit(grad(log_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7221565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:25:07.665443Z",
     "start_time": "2022-06-09T07:25:07.660319Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.9 : Create the log posterior\n",
    "def log_posterior(beta):\n",
    "    '''\n",
    "    Input – beta: a vector of size d+1\n",
    "    Output – log posterior: constant\n",
    "    '''\n",
    "    return log_prior(beta) + log_likelihood(beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68d8f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:25:08.148240Z",
     "start_time": "2022-06-09T07:25:08.143488Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.10 : Evaluates the gradient of the unnormalized log-posterior density\n",
    " \n",
    "def grad_log_posterior(beta):\n",
    "    '''\n",
    "    Input – beta: a vector of size d+1\n",
    "    Output – gradient step of log posterior: beta: a vector of size d+1\n",
    "    '''\n",
    "    return grad_log_prior(beta) + grad_log_likelihood(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-night",
   "metadata": {},
   "source": [
    "# Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc9fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:25:10.090090Z",
     "start_time": "2022-06-09T07:25:10.040661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Q1: independent Metropolis-Hastings\n",
    "def sample_prior():\n",
    "    return multivariate_normal.rvs(mean=np.zeros(DIM), cov=Sigma)\n",
    "\n",
    "n_accept = 0\n",
    "N = 10000\n",
    "current_beta = sample_prior()\n",
    "store_beta = np.zeros((N, DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-excellence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:15:15.529408Z",
     "start_time": "2022-06-09T07:14:34.728654Z"
    }
   },
   "outputs": [],
   "source": [
    "#run the loop\n",
    "for n in range(N):\n",
    "    #sample a proposed state\n",
    "    proposed_beta = sample_prior()\n",
    "\n",
    "    #evaluate posterior density\n",
    "    log_posterior_proposed = log_posterior(proposed_beta)\n",
    "    log_posterior_current = log_posterior(current_beta)\n",
    "\n",
    "    #evaluate transition likelihood\n",
    "    log_transition_proposed = log_prior(proposed_beta)\n",
    "    log_transition_current = log_prior(current_beta)\n",
    "    \n",
    "    #log acceptance prob\n",
    "    log_accept_prob = (log_posterior_proposed + log_transition_current\n",
    "                       - log_posterior_current - log_transition_proposed)\n",
    "\n",
    "    #accept tor reject\n",
    "    uniform = np.random.rand(1) # sample a uniform on [0,1]\n",
    "    if np.log(uniform) < log_accept_prob:\n",
    "        current_beta = proposed_beta.copy() #accept\n",
    "        n_accept += 1\n",
    "\n",
    "    store_beta[n,:] = current_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82675dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:15:15.563000Z",
     "start_time": "2022-06-09T07:15:15.541087Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Acceptance rate: \", n_accept/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-knowing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:15:16.046231Z",
     "start_time": "2022-06-09T07:15:15.575086Z"
    }
   },
   "outputs": [],
   "source": [
    "iteration = np.arange(1,N+1)\n",
    "plt.figure()\n",
    "plt.plot(iteration, store_beta[:,0])\n",
    "plt.plot(iteration, store_beta[:,1])\n",
    "plt.plot(iteration, store_beta[:,2])\n",
    "plt.plot(iteration, store_beta[:,3])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('beta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-output",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:36:08.250748Z",
     "start_time": "2022-06-09T07:34:33.657431Z"
    }
   },
   "outputs": [],
   "source": [
    "#3.2\n",
    "sigma_list = [0.002, 0.02, 0.2]\n",
    "\n",
    "for sigma in sigma_list:\n",
    "    n_accept = 0\n",
    "    current_beta = sample_prior()\n",
    "    store_beta = np.zeros((N, DIM))\n",
    "\n",
    "    for n in range(N):\n",
    "        move = multivariate_normal.rvs(mean=np.zeros(DIM),\n",
    "                                       cov=np.identity(DIM) * sigma**2)\n",
    "        proposed_beta = current_beta + move\n",
    "\n",
    "        #evaluate posterior density\n",
    "        log_posterior_proposed = log_posterior(proposed_beta)\n",
    "        log_posterior_current = log_posterior(current_beta)\n",
    "\n",
    "        #accept tor reject\n",
    "        log_accept_prob = log_posterior_proposed - log_posterior_current\n",
    "        uniform = np.random.rand(1) # sample a uniform on [0,1]\n",
    "        if np.log(uniform) < log_accept_prob:\n",
    "            current_beta = proposed_beta.copy() #accept\n",
    "            n_accept += 1\n",
    "\n",
    "        store_beta[n,:] = current_beta\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(iteration, store_beta[:,1])\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('beta')\n",
    "    plt.title(\"Evolution of beta\")\n",
    "    plt.show()\n",
    "\n",
    "    plot_acf(store_beta[:,1], alpha=None)\n",
    "    plt.ylim([0, 1.1])\n",
    "    plt.xlabel('lag')\n",
    "    plt.ylabel('autocorrelation')\n",
    "    plt.show()\n",
    "    print(f\"Acceptance probability is {n_accept/N}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00d739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-detail",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:16:55.571306Z",
     "start_time": "2022-06-09T07:16:53.244809Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3.3 : Metropolis-adjusted Langevin algorithm\n",
    "import scipy\n",
    "s = 0.08\n",
    "SIG = jnp.eye(DIM) * s**2\n",
    "rng = jax.random.PRNGKey(0)\n",
    "n_accept = 0\n",
    "store_beta = np.zeros((N,DIM))\n",
    "beta = sample_prior()\n",
    "\n",
    "for n in range(N):\n",
    "#     epsilon = jax.random.multivariate_normal(key=rng, mean= jnp.zeros(DIM), cov=SIG)    \n",
    "    epsilon = np.random.multivariate_normal(mean= jnp.zeros(DIM), cov=SIG)    \n",
    "    \n",
    "    proposed_state = beta + s**2 /2 * grad_log_posterior(beta) + epsilon\n",
    "    \n",
    "    pi_y = log_posterior(proposed_state)\n",
    "    pi_x = log_posterior(beta)\n",
    "    q_y = jlogpdataset(proposed_state, mean = beta + s**2 /2 \\\n",
    "                                                 * gradlogdensity(beta) , cov=SIG)\n",
    "    q_x = jlogpdataset(beta , mean = proposed_state + s**2 /2 \\\n",
    "                                                 * gradlogdensity(proposed_state) , cov=SIG)\n",
    "    \n",
    "    \n",
    "    \n",
    "    logacceptprob = float(pi_y + q_x - pi_x - q_y)\n",
    "    \n",
    "    #accept tor reject\n",
    "    uniform = np.random.rand(1) # sample a uniform on [0,1]\n",
    "    if np.log(uniform) < logacceptprob:\n",
    "        beta = proposed_state.copy() #accept\n",
    "        n_accept += 1\n",
    "    store_beta[n,:] = beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-fountain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:16:55.576347Z",
     "start_time": "2022-06-09T07:16:55.576292Z"
    }
   },
   "outputs": [],
   "source": [
    "n_accept/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-hazard",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:16:55.586242Z",
     "start_time": "2022-06-09T07:16:55.586207Z"
    }
   },
   "outputs": [],
   "source": [
    "iteration = np.arange(1,N+1)\n",
    "plt.figure()\n",
    "plt.plot(iteration, store_beta[:,0])\n",
    "plt.plot(iteration, store_beta[:,1])\n",
    "plt.plot(iteration, store_beta[:,2])\n",
    "plt.plot(iteration, store_beta[:,3])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('beta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-curve",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:16:55.591833Z",
     "start_time": "2022-06-09T07:16:55.591732Z"
    }
   },
   "outputs": [],
   "source": [
    "iteration = np.arange(1,N+1)\n",
    "plt.figure()\n",
    "plt.plot(iteration, np.cumsum(store_beta[:,0])/iteration)\n",
    "plt.plot(iteration, np.cumsum(store_beta[:,1])/iteration)\n",
    "plt.plot(iteration, np.cumsum(store_beta[:,2])/iteration)\n",
    "plt.plot(iteration, np.cumsum(store_beta[:,3])/iteration)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('beta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-competition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:16:55.602970Z",
     "start_time": "2022-06-09T07:16:55.602918Z"
    }
   },
   "outputs": [],
   "source": [
    "# auto-correlation function\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plt.figure()\n",
    "plot_acf(store_beta[2000:,0], lags = 30, alpha = None)\n",
    "plot_acf(store_beta[2000:,1], lags = 30, alpha = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-steal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T07:16:55.607340Z",
     "start_time": "2022-06-09T07:16:55.607293Z"
    }
   },
   "outputs": [],
   "source": [
    "#3.4 : Hamiltonian Monte Carlo algorithm\n",
    "import numpy as np\n",
    "from hmc import hamiltonian_dynamics\n",
    "\n",
    "s = 0.08\n",
    "SIG = jnp.eye(DIM) * s**2\n",
    "n_accept = 0\n",
    "store_beta = np.zeros((N,DIM))\n",
    "beta = sample_prior()\n",
    "result = {}\n",
    "\n",
    "# Hamiltonian Monte Carlo, achieve both large move and decent acceptance prob\n",
    "step_size_list = [0.01, 0.05, 0.1]\n",
    "number_step_list = [5,10]\n",
    "for step_size in step_size_list:\n",
    "    for number_step in number_step_list:\n",
    "        # initialize the Markov Chain\n",
    "        beta = sample_prior()\n",
    "\n",
    "        store_beta = np.zeros((N,DIM))\n",
    "        counter = 0\n",
    "        for n in range(N):\n",
    "            velocity = scipy.stats.multivariate_normal.rvs(mean=np.zeros(DIM), cov=np.identity(DIM))\n",
    "            # (1). sample proposed state\n",
    "            proposed_state, proposed_velocity = hamiltonian_dynamics(beta,velocity,step_size,number_step,grad_log_posterior)\n",
    "\n",
    "            # (3). evaluate posterior densities\n",
    "            logprior_proposed = log_posterior(proposed_state)\n",
    "            logprior_current = log_posterior(beta)\n",
    "            numerator = jlogpdf(proposed_velocity,mean=jnp.zeros(DIM),cov=np.identity(DIM))\n",
    "            denominator = jlogpdf(velocity,mean=jnp.zeros(DIM),cov=np.identity(DIM))\n",
    "            # (4). log-acceptance prob\n",
    "            logacceptprob = float(logprior_proposed + numerator  - logprior_current - denominator)\n",
    "            # 5). accept or reject\n",
    "            uniform = np.random.rand(1) # sample a uniform on [0,1]\n",
    "            if np.log(uniform) < logacceptprob:\n",
    "                beta = proposed_state.copy() # accepting, otherwise, stay same beta\n",
    "                counter += 1\n",
    "            # 6). store states\n",
    "            store_beta[n,:] = beta\n",
    "        result[str(step_size) + str(number_step)] = store_beta\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (step_size,number_step,counter/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace plots, should look like stationarity\n",
    "plt.figure()\n",
    "plt.plot(range(N),store_beta[:,1]) # the second dimension\n",
    "plt.show()\n",
    "# auto-correlation, should go down very quickly to 0\n",
    "plot_acf(store_beta[:,1], alpha=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-coordinator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "expected-semiconductor",
   "metadata": {},
   "source": [
    "# Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-century",
   "metadata": {},
   "source": [
    "##### 4.1\n",
    "Under the integral, we can see the expit function and a probability distribution. To estimate this integral, we sample $N$ points $\\{ \\beta^{(t)}, \\space t \\in \\{1, .. , N\\} \\space \\}$ from the distribution $P(\\beta | y_1,..,y_m)$ and then add the obtained values $$\\text{expit}(z^{(t)})$$ where \n",
    "$$z^{(t)}= \\beta_0^{(t)} + \\sum_{j = 1}^n \\beta_j^{(t)} X_{j}.$$\n",
    "We give every point $\\beta^{(t)}$ a weight of $1/N$ so that the total weight is 1 and equals the integral of the probability function. This way, we obtain the method of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 : Approximated predictive probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 : Prediction rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 : Misclassification rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 : Cost function\n",
    "\n",
    "def adjust(y_test, y_pred):\n",
    "    '''\n",
    "    Input – y_test: vector with good/bad credit risk\n",
    "          – y_pred: pred values for good/bad credit risk\n",
    "    Output – average cost – constat'''\n",
    "    f = lamda x,y:  5 if x==0 and y==1\\\n",
    "                    else 1 if x==1 and y==0 \\\n",
    "                    else 0\n",
    "    vf = np.vectorize(f)\n",
    "    return vf(y_test, y_pred)\n",
    "\n",
    "\n",
    "def average_cost(y_test):\n",
    "    '''\n",
    "    Input – y_test: vector with good/bad credit risk\n",
    "    Output – average cost – constat''' \n",
    "    return jnp.sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.6 : Maximum Likelihood Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.7 : Misclassification rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.8 : Prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-patent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8fc5084e69b64ba3a8305ae1e10bbd89152d233669d0e5f5d19e1a4da7e5633"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
